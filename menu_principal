<?xml version="1.0" encoding="UTF-8" standalone="yes"?>

<items>
<items_info>
<title>[COLOR white]•[/COLOR] [B][COLOR red]TACONES[/COLOR][/B]</title>
<genre>ALL</genre>
<description>Addon sin animo de lucro y con fines exclusivamente educativos</description>
<thumbnail>https://i.imgur.com/Umxexj7.png</thumbnail>
<fanart>https://i.imgur.com/t1Br0t4.jpg</fanart>
</items_info>  


<item>
<title>[COLOR white]•[/COLOR] [B][COLOR red]CINE[/COLOR][/B]</title>
<thumbnail>https://i.imgur.com/gyUWTyK.png</thumbnail>
<fanart>https://i.imgur.com/R7oMOZO.jpg</fanart>
<link>http://ignoreme</link>
<externallink>https://raw.githubusercontent.com/830NY/Tacones/main/menu_cine</externallink>
</item>

<item>
<title>[COLOR white]•[/COLOR] [B][COLOR red]DOCUMENTALES[/COLOR][/B]</title>
<thumbnail>https://i.imgur.com/bcXqj1N.png</thumbnail>
<fanart>https://i.imgur.com/22egwFT.jpg</fanart>
<link>$doregex[results]</link>
<regex>
<name>results</name>
<listrepeat><![CDATA[
<title>[B][COLOR red]DOCUMENTALES[/COLOR]     [COLOR white][UPPERCASE][results.param3][/UPPERCASE][/COLOR][/B]</title>
<link>$doregex[docu]</link>
<thumbnail>[results.param2]</thumbnail>
<fanart>https://i.imgur.com/22egwFT.jpg</fanart>
]]></listrepeat>
<expres><![CDATA[#$pyFunction
def GetLSProData(page_data, Cookie_Jar, m):
    import requests
    import re
    import xbmcaddon
    import random
    import xbmcvfs
    import os
    import xbmc
    from bs4 import BeautifulSoup
    HOST = "https://www.documaniatv.com/"
    class UserAgents(object):

        def __init__(self) -> None:
            self.ADDON = xbmcaddon.Addon()
            self.URL = "https://gist.githubusercontent.com/pzb/b4b6f57144aea7827ae4/raw/user-agents.txt"
            self.translatePath = xbmcvfs.translatePath
            PROFILE = self.translatePath(self.ADDON.getAddonInfo('Profile'))
            self.userAgentFile = self.translatePath(
                os.path.join(PROFILE, "user_agents.txt"))
            self.usedAgents = []
            self.userAgents = []

        def prepare(self):
            self.usedAgents = list(self.get_setting("listUserAgents", []))
            self.userAgents = list(filter(lambda userAgent: not userAgent in self.usedAgents, [
                                   userAgent for userAgent in self.downloadFile().splitlines()]))

        def setUserAgent(self, retry=False):
            if not retry:
                currentUserAgent = self.get_setting("currentUserAgent", None)
                if currentUserAgent is not None:
                    return currentUserAgent
            self.prepare()
            selectedUserAgent = random.choice(self.userAgents)
            self.set_setting("listUserAgents", list(
                self.get_setting("listUserAgents", [])).append(selectedUserAgent))
            self.set_setting("currentUserAgent", selectedUserAgent)
            return selectedUserAgent

        def downloadFile(self):
            if os.path.isfile(self.userAgentFile):
                return open(self.userAgentFile).read()
            data = requests.get(self.URL).text
            with open(self.userAgentFile, "w") as file:
                file.write(data)
            return data

        def get_setting(self, name, default=None):
            value = self.ADDON.getSetting(name)
            if not value:
                return default

            if value.startswith("special://"):
                value = self.translatePath(value)

            if value == "true":
                return True
            elif value == "false":
                return False
            else:
                return value

        def set_setting(self, name, value):
            try:
                if isinstance(value, bool):
                    if value:
                        value = "true"
                    else:
                        value = "false"

                elif isinstance(value, int):
                    value = str(value)

                self.ADDON.setSetting(name, value)

            except Exception as ex:
                return None

            return value
    matches = list()
    n = 0
    retryUserAgent = False
    while (n < 5):
        try:
            userAgents = UserAgents()
            selectedUserAgent = userAgents.setUserAgent(retryUserAgent)

            data = requests.get(
                "https://www.documaniatv.com/categorias-y-canales.html", headers={
                    'user-agent':  selectedUserAgent,
                    "referer": HOST
                }).text
            soup = BeautifulSoup(data, "html5lib")
            for li in soup.find("ul", {"class": "pm-ul-browse-categories list-unstyled thumbnails"}
                                ).find_all("li"):
                matches.append((li.find('a').get("href"),
                               f"{li.find('img').get('src')}|User-Agent={selectedUserAgent}&Referer={HOST}", li.find('h3').text, selectedUserAgent))

            if matches is not None and len(matches) > 0:
                break
            else:
                retryUserAgent = True
        except Exception as e:
            retryUserAgent = True
        n += 1
        xbmc.sleep(500)
    return list(sorted(matches, key=lambda docu: docu[2]))
]]></expres>
<page></page>
</regex>
<regex>
<name>docu</name>
<listrepeat><![CDATA[
<title>[B][COLOR white][docu.param1][/COLOR][/B] [COLOR red]([docu.param3])[/COLOR]</title>
<link>$doregex[getUrl]</link>
<thumbnail>[docu.param2]</thumbnail>
<fanart>https://i.imgur.com/GBaQCvw.jpg</fanart>
]]></listrepeat>
<expres><![CDATA[#$pyFunction
def GetLSProData(page_data, Cookie_Jar, m):
    import requests
    from bs4 import BeautifulSoup
    matches = list()
    selectedUserAgent = "[results.param4]"
    data = requests.get(
        m["page"], headers={
            'user-agent': selectedUserAgent
        }).text
    soup = BeautifulSoup(data, "html5lib")
    for li in soup.find("ul", {"id": "pm-grid"}).find_all("li"):
        duration = li.find("span", {"class": "pm-label-duration"}).text
        title = li.find("h3").text
        image = f"{li.find('img').get('src')}|User-Agent={selectedUserAgent}"
        url = li.find('a').get("href")
        matches.append((title, image, duration, url))
    return matches
]]></expres>
<page>[results.param1]</page>
<nextpage><![CDATA[#$pyFunction
def GetLSProData(page_data, Cookie_Jar, m):
    import xbmc
    import requests, re
    selectedUserAgent = "[results.param4]"
    data = requests.get(
        m['page'], headers={
            'user-agent': selectedUserAgent
        }).text
    matches = re.compile(
        r'<link rel="next" href="([^"]+)"').findall(data)[0]
    return matches
]]></nextpage>
</regex>
 <regex>
<name>getUrl</name>
<expres><![CDATA[#$pyFunction
def GetLSProData(page_data, Cookie_Jar, m):
    import requests
    import re
    from urllib.parse import quote
    url = "[docu.param4]"
    embed = "https://www.documaniatv.com/embed/"
    prefix = re.compile(r'_([\d+A-Za-z]+)\.').findall(url)[0]
    embed_url = embed + prefix
    headers = {
        'User-Agent': selectedUserAgent,
        'Connection': 'keep-alive',
    }
    data = requests.get(embed_url, headers=headers, allow_redirects=False).text
    headers['Referer'] = embed_url
    # Thanks to McKlaus
    header_str = '&'.join([f'{k}={quote(v)}' for k, v in headers.items()])
    link = re.compile(
        r'file:\s*(?:"|\')([^"|\']+)(?:"|\'),\s*image').findall(data)[0]
    return f"{link}|{header_str}"
]]></expres>
<page></page>
</regex> 
</item>

<item>
<title>[COLOR white]•[/COLOR] [B][COLOR red]REPETICIONES[/COLOR][COLOR white]       MOTOR [/COLOR][/B]</title>
<thumbnail>https://i.imgur.com/7fME6Vg.png</thumbnail>
<fanart>https://i.imgur.com/IQjr0ib.jpg</fanart>
<link>http://ignoreme</link>
<externallink>https://raw.githubusercontent.com/830NY/Tacones/main/menu_repeticiones</externallink>
</item>

<item>
<title>[COLOR white]•[/COLOR] [B][COLOR red]SERIES [/COLOR][/B]</title>
<thumbnail>https://i.imgur.com/ASLlVXw.png</thumbnail>
<fanart>https://i.imgur.com/8L5Aaw9.jpg</fanart>
<link>http://ignoreme</link>
<externallink>https://raw.githubusercontent.com/830NY/Tacones/main/menu_series</externallink>
</item>

<item>
<title>[COLOR white]•[/COLOR] [B][COLOR red]TDTChannels[/COLOR][COLOR white]       RADIO  [/COLOR][/B]</title>
<link>$doregex[groupname]</link>
<regex>
<name>groupname</name>
<listrepeat><![CDATA[
  <title>[groupname.param1]</title>
  <link>$doregex[tvchannels]</link>
  <thumbnail>https://i.imgur.com/6M9kUPT.png</thumbnail>
  <fanart>https://i.imgur.com/dgmVSVF.jpg</fanart>
]]></listrepeat>
<expres><![CDATA[#$pyFunction
import re,requests
def GetLSProData(page_data,Cookie_Jar,m):
  list = requests.get('https://www.tdtchannels.com/lists/radio.m3u').text
  match = re.compile('group-title="([^"]+)"').findall(list)
  seccion_list = []
  for x in match:
    if x not in seccion_list:
      seccion_list.append(x)
  return seccion_list
]]></expres>
<page></page>
</regex>
<regex>
<name>tvchannels</name>
<listrepeat><![CDATA[
  <title>[tvchannels.param3]</title>
  <link>[tvchannels.param4]</link>
  <thumbnail>[tvchannels.param1]</thumbnail>
  <fanart>https://i.imgur.com/dgmVSVF.jpg</fanart>
]]></listrepeat>
<expres><![CDATA[#$pyFunction
import re, requests
def GetLSProData(page_data,Cookie_Jar,m):
  list = requests.get('https://www.tdtchannels.com/lists/radio.m3u').text
  data = re.findall('EXTINF.*tvg-logo="([^"]+)".group-title="[groupname.param1]".tvg-name="([^"]+)",(.*)\n(.*)',list)
  data.sort()
  return data
]]></expres>
<page></page>
</regex>
<thumbnail>https://i.imgur.com/6M9kUPT.png</thumbnail>
<fanart>https://i.imgur.com/dgmVSVF.jpg</fanart>
</item>


<item>
<title>[COLOR white]•[/COLOR] [B][COLOR red]TDTChannels[/COLOR][COLOR white]       TELEVISION  [/COLOR][/B]</title>
<link>$doregex[groupname]</link>
<regex>
<name>groupname</name>
<listrepeat><![CDATA[
  <title>[groupname.param1]</title>
  <link>$doregex[tvchannels]</link>
  <thumbnail>https://i.imgur.com/6M9kUPT.png</thumbnail>
<fanart>https://i.imgur.com/IJupcZz.jpg</fanart>
]]></listrepeat>
<expres><![CDATA[#$pyFunction
import re,requests
def GetLSProData(page_data,Cookie_Jar,m):
  list = requests.get('https://www.tdtchannels.com/lists/tv.m3u').text
  match = re.compile('group-title="([^"]+)"').findall(list)
  seccion_list = []
  for x in match:
    if x not in seccion_list:
      seccion_list.append(x)
  return seccion_list
]]></expres>
<page></page>
</regex>
<regex>
<name>tvchannels</name>
<listrepeat><![CDATA[
  <title>[tvchannels.param3]</title>
  <link>[tvchannels.param4]</link>
  <thumbnail>[tvchannels.param1]</thumbnail>
  <fanart>https://i.imgur.com/IJupcZz.jpg</fanart>
]]></listrepeat>
<expres><![CDATA[#$pyFunction
import re, requests
def GetLSProData(page_data,Cookie_Jar,m):
  list = requests.get('https://www.tdtchannels.com/lists/tv.m3u').text
  data = re.findall('EXTINF.*tvg-logo="([^"]+)".group-title="[groupname.param1]".tvg-name="([^"]+)",(.*)\n(.*)',list)
  data.sort()
  return data
]]></expres>
<page></page>
</regex>
<thumbnail>https://i.imgur.com/6M9kUPT.png</thumbnail>
<fanart>https://i.imgur.com/IJupcZz.jpg</fanart>
</item>

<item>
<title>[COLOR red]•[/COLOR] [B][COLOR white]ADDON TACONES[/COLOR][COLOR red]                        LA MALA DE LA NOVELA[/COLOR][/B]</title>
<utube>Sgnp9ZaXHFw</utube>
<thumbnail>https://i.imgur.com/Umxexj7.png</thumbnail>
<fanart>https://i.imgur.com/t1Br0t4.jpg</fanart>
</item>


<item>
<title>[COLOR red]•[/COLOR] [B][COLOR white]GRUPO AYUDA TELEGRAM[/COLOR][COLOR red]       @KODISPAIN_1[/COLOR][/B]</title>
<utube>Sgnp9ZaXHFw</utube>
<thumbnail>https://i.imgur.com/Px871XF.jpg</thumbnail>
<fanart>https://i.imgur.com/P9rlq5c.jpg</fanart>
</item>

</items>
